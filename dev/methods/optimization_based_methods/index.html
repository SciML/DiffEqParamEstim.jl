<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Optimization-Based Methods · DiffEqParamEstim.jl</title><meta name="title" content="Optimization-Based Methods · DiffEqParamEstim.jl"/><meta property="og:title" content="Optimization-Based Methods · DiffEqParamEstim.jl"/><meta property="twitter:title" content="Optimization-Based Methods · DiffEqParamEstim.jl"/><meta name="description" content="Documentation for DiffEqParamEstim.jl."/><meta property="og:description" content="Documentation for DiffEqParamEstim.jl."/><meta property="twitter:description" content="Documentation for DiffEqParamEstim.jl."/><meta property="og:url" content="https://docs.sciml.ai/DiffEqParamEstim/stable/methods/optimization_based_methods/"/><meta property="twitter:url" content="https://docs.sciml.ai/DiffEqParamEstim/stable/methods/optimization_based_methods/"/><link rel="canonical" href="https://docs.sciml.ai/DiffEqParamEstim/stable/methods/optimization_based_methods/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="DiffEqParamEstim.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">DiffEqParamEstim.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">DiffEqParamEstim.jl: Parameter Estimation for Differential Equations</a></li><li><a class="tocitem" href="../../getting_started/">Getting Started with Optimization-Based ODE Parameter Estimation</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/global_optimization/">Global Optimization via NLopt</a></li><li><a class="tocitem" href="../../tutorials/generalized_likelihood/">Generalized Likelihood Inference</a></li><li><a class="tocitem" href="../../tutorials/stochastic_evaluations/">Parameter Estimation for Stochastic Differential Equations and Ensembles</a></li><li><a class="tocitem" href="../../tutorials/ensemble/">Fitting Ensembles of ODE Models to Data</a></li></ul></li><li><span class="tocitem">Methods</span><ul><li><a class="tocitem" href="../recommended_methods/">Recommended Methods</a></li><li class="is-active"><a class="tocitem" href>Optimization-Based Methods</a><ul class="internal"><li><a class="tocitem" href="#The-Objective-Function-Builders"><span>The Objective Function Builders</span></a></li><li><a class="tocitem" href="#Detailed-Explanations-of-Arguments"><span>Detailed Explanations of Arguments</span></a></li><li><a class="tocitem" href="#Using-the-Objectives-for-MAP-estimates"><span>Using the Objectives for MAP estimates</span></a></li></ul></li><li><a class="tocitem" href="../collocation_loss/">Two Stage method (Non-Parametric Collocation)</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Methods</a></li><li class="is-active"><a href>Optimization-Based Methods</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Optimization-Based Methods</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/DiffEqParamEstim.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/DiffEqParamEstim.jl/blob/master/docs/src/methods/optimization_based_methods.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Optimization-Based-Methods"><a class="docs-heading-anchor" href="#Optimization-Based-Methods">Optimization-Based Methods</a><a id="Optimization-Based-Methods-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization-Based-Methods" title="Permalink"></a></h1><h2 id="The-Objective-Function-Builders"><a class="docs-heading-anchor" href="#The-Objective-Function-Builders">The Objective Function Builders</a><a id="The-Objective-Function-Builders-1"></a><a class="docs-heading-anchor-permalink" href="#The-Objective-Function-Builders" title="Permalink"></a></h2><h3 id="Standard-Nonlinear-Regression"><a class="docs-heading-anchor" href="#Standard-Nonlinear-Regression">Standard Nonlinear Regression</a><a id="Standard-Nonlinear-Regression-1"></a><a class="docs-heading-anchor-permalink" href="#Standard-Nonlinear-Regression" title="Permalink"></a></h3><p><code>build_loss_objective</code> builds an objective function to be used with Optim.jl and MathProgBase-associated solvers like NLopt.</p><pre><code class="language-julia hljs">function build_loss_objective(prob::DEProblem, alg, loss,
        adtype = SciMLBase.NoAD(),
        regularization = nothing;
        priors = nothing,
        prob_generator = STANDARD_PROB_GENERATOR,
        kwargs...)
end</code></pre><p>The first argument is the <code>DEProblem</code> to solve, and next is the <code>alg</code> to use. The <code>alg</code> must match the problem type, which can be any <code>DEProblem</code> (ODEs, SDEs, DAEs, DDEs, etc.). <code>regularization</code> defaults to nothing, which has no regularization function. The extra keyword arguments are passed to the differential equation solver.</p><h3 id="Multiple-Shooting"><a class="docs-heading-anchor" href="#Multiple-Shooting">Multiple Shooting</a><a id="Multiple-Shooting-1"></a><a class="docs-heading-anchor-permalink" href="#Multiple-Shooting" title="Permalink"></a></h3><p>Multiple Shooting is often used in Boundary Value Problems (BVP) and is more robust than the regular objective function used in these problems. It proceeds as follows:</p><ul><li>Divide up the time span into short time periods and solve the equation with the current parameters which here consist of both, the parameters of the differential equations and also the initial values for the short time periods.</li><li>This objective additionally involves a discontinuity error term that imposes higher cost if the end of the solution of one time period doesn&#39;t match the beginning of the next one.</li><li>Merge the solutions from the shorter intervals and then calculate the loss.</li></ul><pre><code class="language-julia hljs">function multiple_shooting_objective(prob::DiffEqBase.DEProblem, alg, loss,
        adtype = SciMLBase.NoAD(),
        regularization = nothing;
        priors = nothing,
        discontinuity_weight = 1.0,
        prob_generator = STANDARD_PROB_GENERATOR,
        kwargs...)
end</code></pre><p>For consistency <code>multiple_shooting_objective</code> takes exactly the same arguments as <code>build_loss_objective</code>. It also has the option for <code>discontinuity_weight</code> as a keyword argument, which assigns weight to the error occurring due to the discontinuity that arises from the breaking up of the time span.</p><h2 id="Detailed-Explanations-of-Arguments"><a class="docs-heading-anchor" href="#Detailed-Explanations-of-Arguments">Detailed Explanations of Arguments</a><a id="Detailed-Explanations-of-Arguments-1"></a><a class="docs-heading-anchor-permalink" href="#Detailed-Explanations-of-Arguments" title="Permalink"></a></h2><h3 id="The-Loss-Function"><a class="docs-heading-anchor" href="#The-Loss-Function">The Loss Function</a><a id="The-Loss-Function-1"></a><a class="docs-heading-anchor-permalink" href="#The-Loss-Function" title="Permalink"></a></h3><pre><code class="language-julia hljs">loss(sol)</code></pre><p>is the function, which reduces the problem&#39;s solution to a scalar, which the optimizer will try to minimize. While this is very flexible, two convenience routines are included for fitting to data with standard cost functions:</p><pre><code class="language-julia hljs">L2Loss(t, data; differ_weight = nothing, data_weight = nothing,
    colloc_grad = nothing, dudt = nothing)</code></pre><p>where <code>t</code> is the set of timepoints which the data are found at, and <code>data</code> are the values that are known where each column corresponds to measures of the values of the system. <code>L2Loss</code> is an optimized version of the L2-distance. The <code>data_weight</code> is a scalar or vector of weights for the loss function which must match the size of the data. Note that minimization of a weighted <code>L2Loss</code> is equivalent to maximum likelihood estimation of a heteroskedastic Normally distributed likelihood. <code>differ_weight</code> allows one to add a weight on the first differencing terms <code>sol[i+1]-sol[i]</code> against the data first differences. This smooths out the loss term and can make it easier to fit strong solutions of stochastic models, but is zero (nothing) by default. Additionally, <code>colloc_grad</code> allows one to give a matrix of the collocation gradients for the data. This is used to add an interpolation derivative term, like the two-stage method. A convenience function <code>colloc_grad(t,data)</code> returns a collocation gradient from a 3rd order spline calculated by Dierckx.jl, which can be used as the <code>colloc_grad</code>. Note that, with a collocation gradient and regularization, this loss is equivalent to a 4DVAR.</p><p>Additionally, we include a more flexible log-likelihood approach:</p><pre><code class="language-julia hljs">LogLikeLoss(t, distributions, diff_distributions = nothing)</code></pre><p>In this case, there are two forms. The simple case is where <code>distributions[i,j]</code> is the likelihood distributions from a <code>UnivariateDistribution</code> from <a href="https://juliastats.github.io/Distributions.jl/dev/">Distributions.jl</a>, where it corresponds to the likelihood at <code>t[i]</code> for component <code>j</code>. The second case is where <code>distributions[i]</code> is a <code>MultivariateDistribution</code> which corresponds to the likelihood at <code>t[i]</code> over the vector of components. This likelihood function then calculates the negative of the total log-likelihood over time as its objective value (negative since optimizers generally find minimums, and thus this corresponds to maximum likelihood estimation). The third term, <code>diff_distributions</code>, acts similarly but allows putting a distribution on the first difference terms <code>sol[i+1]-sol[i]</code>.</p><p>Note that these distributions can be generated via <code>fit_mle</code> on some dataset against some chosen distribution type.</p><h3 id="Note-About-Loss-Functions"><a class="docs-heading-anchor" href="#Note-About-Loss-Functions">Note About Loss Functions</a><a id="Note-About-Loss-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Note-About-Loss-Functions" title="Permalink"></a></h3><p>For parameter estimation problems, it&#39;s not uncommon for the optimizers to hit unstable regions of parameter space. This causes warnings that the solver exited early, and the built-in loss functions like <code>L2Loss</code> automatically handle this. However, if using a user-supplied loss function, you should make sure it&#39;s robust to these issues. One common pattern is to apply infinite loss when the integration is not successful. Using the retcodes, this can be done via:</p><pre><code class="language-julia hljs">function my_loss_function(sol)
    tot_loss = 0.0
    if any((!SciMLBase.successful_retcode(s.retcode) for s in sol))
        tot_loss = Inf
    else
        # calculation for the loss here
    end
    tot_loss
end</code></pre><h3 id="fd"><a class="docs-heading-anchor" href="#fd">Note on First Differencing</a><a id="fd-1"></a><a class="docs-heading-anchor-permalink" href="#fd" title="Permalink"></a></h3><pre><code class="language-julia hljs">L2Loss(t, data, differ_weight = 0.3, data_weight = 0.7)</code></pre><p>First differencing incorporates the differences of data points at consecutive time points which adds more information about the trajectory in the loss function. Adding first differencing is helpful in cases where the <code>L2Loss</code> alone leads to non-identifiable parameters, but adding a first differencing term makes it more identifiable. This can be noted on stochastic differential equation models, where this aims to capture the autocorrelation and therefore helps us avoid getting the same stationary distribution despite different trajectories and thus wrong parameter estimates.</p><h3 id="The-Regularization-Function"><a class="docs-heading-anchor" href="#The-Regularization-Function">The Regularization Function</a><a id="The-Regularization-Function-1"></a><a class="docs-heading-anchor-permalink" href="#The-Regularization-Function" title="Permalink"></a></h3><p>The regularization can be any function of <code>p</code>, the parameter vector:</p><pre><code class="language-julia hljs">regularization(p)</code></pre><p>The <code>Regularization</code> helper function builds a regularization using a penalty function <code>penalty</code> from <a href="https://github.com/JuliaML/PenaltyFunctions.jl">PenaltyFunctions.jl</a>:</p><pre><code class="language-julia hljs">reg = Regularization(λ, penalty = L2Penalty())
build_loss_objective(prob, alg, loss, SciMLBase.NoAD(), reg)

using Optimization, Zygote
build_loss_objective(prob, alg, loss, Optimization.AutoZygote(), reg)</code></pre><p>The regularization defaults to L2 if no penalty function is specified. <code>λ</code> is the weight parameter for the addition of the regularization term.</p><h3 id="Using-automatic-differentiation"><a class="docs-heading-anchor" href="#Using-automatic-differentiation">Using automatic differentiation</a><a id="Using-automatic-differentiation-1"></a><a class="docs-heading-anchor-permalink" href="#Using-automatic-differentiation" title="Permalink"></a></h3><p>To use derivatives with optimization solvers, Optimization.jl&#39;s <code>adtype</code> argument as described <a href="https://docs.sciml.ai/Optimization/stable/getting_started/#Controlling-Gradient-Calculations-(Automatic-Differentiation)">here</a> should be used with the wrapper subpackage OptimizationOptimJL, OptimizationNLopt etc.</p><pre><code class="language-julia hljs">using Optimization, ForwardDiff
build_loss_objective(prob, alg, loss, Optimization.AutoForwardDiff())
multiple_shooting_objective(prob, alg, loss, Optimization.AutoForwardDiff())</code></pre><h3 id="The-Problem-Generator-Function"><a class="docs-heading-anchor" href="#The-Problem-Generator-Function">The Problem Generator Function</a><a id="The-Problem-Generator-Function-1"></a><a class="docs-heading-anchor-permalink" href="#The-Problem-Generator-Function" title="Permalink"></a></h3><p>The argument <code>prob_generator</code> allows one to specify a function for generating new problems from a given parameter set. By default, this just builds a new problem which fixes the element types in a way that&#39;s autodifferentiation compatible and adds the new parameter vector <code>p</code>. For example, the code for this is:</p><pre><code class="language-julia hljs">prob_generator = (prob, p) -&gt; remake(prob, u0 = convert.(eltype(p), prob.u0), p = p)</code></pre><p>Then the new problem with these new values is returned.</p><p>One can use this to change the meaning of the parameters using this function. For example, if one instead wanted to optimize the initial conditions for a function without parameters, you could change this to:</p><pre><code class="language-julia hljs">prob_generator = (prob, p) -&gt; remake(prob.f, u0 = p)</code></pre><p>which simply uses <code>p</code> as the initial condition in the initial value problem.</p><h2 id="Using-the-Objectives-for-MAP-estimates"><a class="docs-heading-anchor" href="#Using-the-Objectives-for-MAP-estimates">Using the Objectives for MAP estimates</a><a id="Using-the-Objectives-for-MAP-estimates-1"></a><a class="docs-heading-anchor-permalink" href="#Using-the-Objectives-for-MAP-estimates" title="Permalink"></a></h2><p>You can also add a prior option to <code>build_loss_objective</code> and <code>multiple_shooting_objective</code> that essentially turns it into MAP by multiplying the log-likelihood (the cost) by the prior. The option is available as the keyword argument <code>priors</code>, it can take in either an array of univariate distributions for each of the parameters or a multivariate distribution.</p><pre><code class="language-julia hljs">ms_obj = multiple_shooting_objective(ms_prob, Tsit5(), L2Loss(t, data); priors = priors,
    discontinuity_weight = 1.0, abstol = 1e-12,
    reltol = 1e-12)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../recommended_methods/">« Recommended Methods</a><a class="docs-footer-nextpage" href="../collocation_loss/">Two Stage method (Non-Parametric Collocation) »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.3.0 on <span class="colophon-date" title="Monday 8 April 2024 08:11">Monday 8 April 2024</span>. Using Julia version 1.10.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
